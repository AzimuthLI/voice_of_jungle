{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import librosa\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import transformers\n",
    "from transformers import ASTConfig, ASTFeatureExtractor, ASTModel\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from time import time\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print system info \n",
    "!nvidia-smi\n",
    "!python --version\n",
    "\n",
    "# print pytorch lightning version\n",
    "print(f\"Pytorch Version: {torch.__version__}\")\n",
    "print(f\"Transformers Version: {transformers.__version__}\")\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA Version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(log_file='log.txt'):\n",
    "    import logging\n",
    "    import sys\n",
    "    \n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(message)s')\n",
    "    # Logging to file\n",
    "    file_handler = logging.FileHandler(log_file)\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "    # Logging to console\n",
    "    ch = logging.StreamHandler(sys.stdout)\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "def wandb_init(project_name, run_name, config):\n",
    "    config_dict = {\n",
    "        k: v for k, v in config.__dict__.items() if not k.startswith('_') and not callable(v) and k != 'copy'\n",
    "    }\n",
    "    run = wandb.init(project=project_name, name=run_name, config=config_dict)\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVE_FOLDER = \".\" #\"/content/drive/MyDrive/Colab Notebooks\"\n",
    "KEEP_COLS = ['category_number', 'common_name', 'audio_length', 'type', 'remarks', 'quality', 'scientific_name', 'mp3_link', 'region']\n",
    "\n",
    "class Config:\n",
    "    dataset_dir = f\"{DRIVE_FOLDER}/Audio_XenoCanto\"\n",
    "    labels_list = f\"{DRIVE_FOLDER}/xeno_labels.csv\"\n",
    "    model_name = \"BirdAST_Baseline_GroupKFold\"\n",
    "    backbone_name = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "    n_classes = 728 # number of classes in the dataset\n",
    "    audio_sr = 16000 #Hz\n",
    "    segment_length = 10  #s\n",
    "    fft_window = 0.025 #s\n",
    "    hop_window_length = 0.01 #s\n",
    "    n_mels = 128\n",
    "    low_cut = 1000 #Hz\n",
    "    high_cut = 8000 #Hz\n",
    "    top_db = 100\n",
    "    batch_size = 16 #4 \n",
    "    num_workers = 0\n",
    "    n_splits = 5\n",
    "    log_dir = f\"{DRIVE_FOLDER}/training_logs\"\n",
    "    max_lr = 1e-5\n",
    "    epochs = 10\n",
    "    weight_decay = 0.01\n",
    "    lr_final_div = 1000\n",
    "    amp = True\n",
    "    grad_accum_steps = 1\n",
    "    max_grad_norm = 1e7\n",
    "    print_epoch_freq = 1\n",
    "    print_freq = 500\n",
    "    random_seed = 2046\n",
    "    \n",
    "    @classmethod\n",
    "    def copy(cls):\n",
    "        new_class = type('CustomConfig', (cls,), {k: v for k, v in cls.__dict__.items() if not k.startswith('__') and not callable(v)})\n",
    "        return new_class\n",
    "    \n",
    "config = Config.copy()\n",
    "\n",
    "if not os.path.exists(config.log_dir):\n",
    "    os.makedirs(config.log_dir)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed_everything(config.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes with less than 2 samples: 72\n",
      "Number of classes in dataset: 728\n",
      "Number of samples: 11171\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>category_number</th>\n",
       "      <th>common_name</th>\n",
       "      <th>audio_length</th>\n",
       "      <th>type</th>\n",
       "      <th>remarks</th>\n",
       "      <th>quality</th>\n",
       "      <th>mp3_link</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>region</th>\n",
       "      <th>file_exists</th>\n",
       "      <th>species_id</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/XC228210-Blue-crowned_Manakin_B_9369_0.wav</td>\n",
       "      <td>XC228210</td>\n",
       "      <td>Blue-crowned Manakin</td>\n",
       "      <td>0:20</td>\n",
       "      <td>call</td>\n",
       "      <td>ID certainty 80%. (Archiv. tape 393 side A tra...</td>\n",
       "      <td>B</td>\n",
       "      <td>//xeno-canto.org/sounds/uploaded/OOECIWCSWV/XC...</td>\n",
       "      <td>Lepidothrix_coronata</td>\n",
       "      <td>amazonas</td>\n",
       "      <td>True</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/XC228210-Blue-crowned_Manakin_B_9369_1.wav</td>\n",
       "      <td>XC228210</td>\n",
       "      <td>Blue-crowned Manakin</td>\n",
       "      <td>0:20</td>\n",
       "      <td>call</td>\n",
       "      <td>ID certainty 80%. (Archiv. tape 393 side A tra...</td>\n",
       "      <td>B</td>\n",
       "      <td>//xeno-canto.org/sounds/uploaded/OOECIWCSWV/XC...</td>\n",
       "      <td>Lepidothrix_coronata</td>\n",
       "      <td>amazonas</td>\n",
       "      <td>True</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/XC200163-PIPCOR03_0.wav</td>\n",
       "      <td>XC200163</td>\n",
       "      <td>Blue-crowned Manakin</td>\n",
       "      <td>0:42</td>\n",
       "      <td>call, song</td>\n",
       "      <td>left bank of rio Negro - terra firme forest, w...</td>\n",
       "      <td>C</td>\n",
       "      <td>//xeno-canto.org/sounds/uploaded/DGVLLRYDXS/XC...</td>\n",
       "      <td>Lepidothrix_coronata</td>\n",
       "      <td>amazonas</td>\n",
       "      <td>True</td>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/XC200163-PIPCOR03_1.wav</td>\n",
       "      <td>XC200163</td>\n",
       "      <td>Blue-crowned Manakin</td>\n",
       "      <td>0:42</td>\n",
       "      <td>call, song</td>\n",
       "      <td>left bank of rio Negro - terra firme forest, w...</td>\n",
       "      <td>C</td>\n",
       "      <td>//xeno-canto.org/sounds/uploaded/DGVLLRYDXS/XC...</td>\n",
       "      <td>Lepidothrix_coronata</td>\n",
       "      <td>amazonas</td>\n",
       "      <td>True</td>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/XC200163-PIPCOR03_2.wav</td>\n",
       "      <td>XC200163</td>\n",
       "      <td>Blue-crowned Manakin</td>\n",
       "      <td>0:42</td>\n",
       "      <td>call, song</td>\n",
       "      <td>left bank of rio Negro - terra firme forest, w...</td>\n",
       "      <td>C</td>\n",
       "      <td>//xeno-canto.org/sounds/uploaded/DGVLLRYDXS/XC...</td>\n",
       "      <td>Lepidothrix_coronata</td>\n",
       "      <td>amazonas</td>\n",
       "      <td>True</td>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         file_name category_number  \\\n",
       "0  data/XC228210-Blue-crowned_Manakin_B_9369_0.wav        XC228210   \n",
       "1  data/XC228210-Blue-crowned_Manakin_B_9369_1.wav        XC228210   \n",
       "2                     data/XC200163-PIPCOR03_0.wav        XC200163   \n",
       "3                     data/XC200163-PIPCOR03_1.wav        XC200163   \n",
       "4                     data/XC200163-PIPCOR03_2.wav        XC200163   \n",
       "\n",
       "            common_name audio_length        type  \\\n",
       "0  Blue-crowned Manakin         0:20        call   \n",
       "1  Blue-crowned Manakin         0:20        call   \n",
       "2  Blue-crowned Manakin         0:42  call, song   \n",
       "3  Blue-crowned Manakin         0:42  call, song   \n",
       "4  Blue-crowned Manakin         0:42  call, song   \n",
       "\n",
       "                                             remarks quality  \\\n",
       "0  ID certainty 80%. (Archiv. tape 393 side A tra...       B   \n",
       "1  ID certainty 80%. (Archiv. tape 393 side A tra...       B   \n",
       "2  left bank of rio Negro - terra firme forest, w...       C   \n",
       "3  left bank of rio Negro - terra firme forest, w...       C   \n",
       "4  left bank of rio Negro - terra firme forest, w...       C   \n",
       "\n",
       "                                            mp3_link       scientific_name  \\\n",
       "0  //xeno-canto.org/sounds/uploaded/OOECIWCSWV/XC...  Lepidothrix_coronata   \n",
       "1  //xeno-canto.org/sounds/uploaded/OOECIWCSWV/XC...  Lepidothrix_coronata   \n",
       "2  //xeno-canto.org/sounds/uploaded/DGVLLRYDXS/XC...  Lepidothrix_coronata   \n",
       "3  //xeno-canto.org/sounds/uploaded/DGVLLRYDXS/XC...  Lepidothrix_coronata   \n",
       "4  //xeno-canto.org/sounds/uploaded/DGVLLRYDXS/XC...  Lepidothrix_coronata   \n",
       "\n",
       "     region  file_exists  species_id  group_id  \n",
       "0  amazonas         True         329         0  \n",
       "1  amazonas         True         329         0  \n",
       "2  amazonas         True         329         1  \n",
       "3  amazonas         True         329         1  \n",
       "4  amazonas         True         329         1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_audio_meta = pd.read_csv(f\"{config.dataset_dir}/metadata.csv\", nrows=None)\n",
    "df_audio_meta = df_audio_meta.dropna().reset_index(drop=True)\n",
    "\n",
    "# Filter out files that do not exist\n",
    "df_audio_meta['file_exists'] = df_audio_meta['file_name'].apply(lambda x: os.path.exists(f\"{config.dataset_dir}/{x}\"))\n",
    "df_audio_meta = df_audio_meta[df_audio_meta['file_exists']].reset_index(drop=True)\n",
    "\n",
    "# parse scientific names\n",
    "df_audio_meta['scientific_name'] = df_audio_meta['scientific_name'].apply(lambda x: \"_\".join(x.split(\" \")))\n",
    "\n",
    "# drop species with less than 2 samples\n",
    "class_counts = df_audio_meta['scientific_name'].value_counts()\n",
    "print(f\"Number of classes with less than 2 samples: {len(class_counts[class_counts < 2])}\")\n",
    "\n",
    "df_audio_meta = df_audio_meta[df_audio_meta['scientific_name'].isin(class_counts[class_counts > 1].index)].copy().reset_index(drop=True)\n",
    "\n",
    "# encode scientific names to label ids\n",
    "label_ids_list = df_audio_meta['scientific_name'].unique().tolist()\n",
    "label_ids_list.sort()\n",
    "label_to_id = {label: i for i, label in enumerate(label_ids_list)}\n",
    "df_audio_meta['species_id'] = df_audio_meta['scientific_name'].map(label_to_id)\n",
    "\n",
    "# save the label mapping\n",
    "label_mapping = pd.DataFrame(label_to_id.items(), columns=['scientific_name', 'species_id'])\n",
    "label_mapping.to_csv(f\"{config.log_dir}/{config.model_name}_label_map.csv\", index=False)\n",
    "\n",
    "# drop samples with no labels\n",
    "df_audio_meta.dropna(subset=['species_id'], inplace=True)\n",
    "df_audio_meta.reset_index(drop=True, inplace=True)\n",
    "df_audio_meta['species_id'] = df_audio_meta['species_id'].astype(int)\n",
    "\n",
    "print(f\"Number of classes in dataset: {df_audio_meta['species_id'].nunique()}\")\n",
    "print(f'Number of samples:', len(df_audio_meta))\n",
    "\n",
    "# save the number of classes in the config\n",
    "config.n_classes = df_audio_meta['species_id'].nunique()\n",
    "\n",
    "# encode mp3 links to group ids for 5-folds\n",
    "group_ids = df_audio_meta['mp3_link'].unique().tolist()\n",
    "group_ids_map = {group_id: i for i, group_id in enumerate(group_ids)}\n",
    "df_audio_meta['group_id'] = df_audio_meta['mp3_link'].map(group_ids_map)\n",
    "\n",
    "df_audio_meta.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['//xeno-canto.org/sounds/uploaded/BZVYBRUAAE/XC764534-221118_06_Maranon-Spinetail_Valle-de-Utcubamba,-Amazonas,-Peru_17-November-2022.mp3',\n",
       "        '//xeno-canto.org/sounds/uploaded/TGBFXDVERJ/XC763511-Synallaxis-maronica_Bagua-grande_MixPre-1746.mp3'],\n",
       "       dtype=object),\n",
       " array(['amazonas'], dtype=object),\n",
       " array(['Synallaxis_maranonica'], dtype=object))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = df_audio_meta[df_audio_meta['species_id'] == 619] \n",
    "tmp['mp3_link'].unique(), tmp['region'].unique(), tmp['scientific_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all species in greater_manaus are in amazonas\n",
    "greater_manaus = df_audio_meta[df_audio_meta['region'] == 'greater_manaus']\n",
    "amazonas = df_audio_meta[df_audio_meta['region'] == 'amazonas']\n",
    "\n",
    "print('Number of species in greater_manaus:', len(greater_manaus['scientific_name'].unique()))\n",
    "print('Number of species in amazonas:', len(amazonas['scientific_name'].unique()))\n",
    "\n",
    "shared_species = [x for x in greater_manaus['scientific_name'].unique().tolist() if x in amazonas['scientific_name'].unique().tolist()]\n",
    "\n",
    "print('Number of species in both regions:', len(shared_species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of samples per class and weights for focal loss\n",
    "class_counts = df_audio_meta['species_id'].value_counts().sort_index()\n",
    "class_weights = 1 / class_counts\n",
    "\n",
    "# plot the distribution of the number of samples per class\n",
    "fig, ax = plt.subplots(figsize=(12, 3))\n",
    "\n",
    "class_counts_sorted = class_counts.sort_values(ascending=False)\n",
    "class_counts.sort_values(ascending=False)[0:300].plot(ax=ax, kind='bar', color='blue')\n",
    "ax.set_xticklabels([])\n",
    "ax.tick_params(axis='y', labelcolor='black', labelsize=12, labelfontfamily='serif')\n",
    "ax.set_xlabel('Bird species (sorted by number of samples)', fontsize=14, fontfamily='serif')\n",
    "ax.set_ylabel('Number of Samples', fontsize=14, fontfamily='serif')\n",
    "ax.set_title('Number of Samples per Bird Species [Xeno-Canto]', fontsize=18, fontfamily='serif')\n",
    "ax.set_facecolor('#f3ede2')\n",
    "fig.set_facecolor('#f3ede2')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a sample audio file & spectrogram\n",
    "sample = df_audio_meta.sample(1)\n",
    "\n",
    "audio_file = f\"{config.dataset_dir}/{sample['file_name'].values[0]}\"\n",
    "print(audio_file)\n",
    "\n",
    "y, sr = librosa.load(audio_file, sr=config.audio_sr)\n",
    "\n",
    "meta_str = f\"{sample['common_name'].values[0]} | {sample['scientific_name'].values[0]} | {sample['region'].values[0]}\"\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(9, 4))\n",
    "\n",
    "axes[0].plot(y)\n",
    "axes[0].set_title(meta_str, fontsize=14, fontfamily='serif')\n",
    "axes[0].set_xlabel('Time (samples)', fontsize=12, fontfamily='serif')\n",
    "axes[0].set_ylabel('Amplitude', fontsize=12, fontfamily='serif')\n",
    "\n",
    "mel_spec = ASTFeatureExtractor()(y, sampling_rate=sr, padding=\"max_length\", return_tensors=\"np\")[\"input_values\"]\n",
    "\n",
    "axes[1].imshow(mel_spec[0].T, aspect='auto', origin='lower', cmap='plasma')\n",
    "axes[1].set_xlabel('Time (frames)', fontsize=12, fontfamily='serif')\n",
    "axes[1].set_ylabel('Mel Frequency', fontsize=12, fontfamily='serif')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_facecolor('#f3ede2')\n",
    "    \n",
    "fig.set_facecolor('#f3ede2')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdSongDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df_audio_meta, config):\n",
    "        self.df_audio_meta = df_audio_meta\n",
    "        self.feature_extractor = ASTFeatureExtractor()\n",
    "        self.config = config\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df_audio_meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df_audio_meta.iloc[idx]\n",
    "        audio_path = f\"{self.config.dataset_dir}/{row['file_name']}\"\n",
    "        audio_arr, sr = self.get_audio(audio_path)\n",
    "        spec = self.feature_extractor(audio_arr, sampling_rate=sr, padding=\"max_length\", return_tensors=\"pt\")\n",
    "        return spec['input_values'].squeeze(0), row['species_id']\n",
    "\n",
    "    def get_audio(self, audio_path):\n",
    "        audio, sr = librosa.load(audio_path, sr=self.config.audio_sr)\n",
    "        return audio, sr\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs = [x[0] for x in batch]\n",
    "    targets = [x[1] for x in batch]\n",
    "    data_dict = {\n",
    "        \"input_ids\": torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0),\n",
    "        \"labels\": torch.tensor(targets)\n",
    "    }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test the dataset and dataloader\n",
    "# bs_dataset = BirdSongDataset(df_audio_meta, config)\n",
    "# bs_dataloader = DataLoader(bs_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# for batch in bs_dataloader:\n",
    "#     print(batch['input_ids'].shape)\n",
    "#     print(batch['labels'])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss_fn and eval_fn\n",
    "class FocalLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, gamma=0, alpha=None, reduction='mean', device=DEVICE):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        \n",
    "        if isinstance(alpha, (float, int, )): \n",
    "            self.alpha = torch.Tensor([alpha, 1-alpha])\n",
    "        elif isinstance(alpha, (list, np.ndarray)): \n",
    "            self.alpha = torch.tensor(alpha, dtype=torch.float32, device=device)\n",
    "        else:\n",
    "            raise TypeError('Invalid alpha type')\n",
    "        \n",
    "        self.ce_loss = nn.CrossEntropyLoss(weight=self.alpha, reduction='none')\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce_loss = self.ce_loss(logits, targets) # nn.CrossEntropyLoss already applies log_softmax\n",
    "        pt = torch.exp(-ce_loss) # CE = -log(p_t) -> p_t = exp(-CE)\n",
    "        \n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        return_method = {\n",
    "            'mean': torch.mean,\n",
    "            'sum': torch.sum,\n",
    "            'none': lambda x: x\n",
    "        }\n",
    "        \n",
    "        return return_method[self.reduction](focal_loss)\n",
    "        \n",
    "# eval_fn\n",
    "class ROC_AUC_Score(nn.Module):\n",
    "    \n",
    "    def __init__(self, config, average='macro', multi_class='ovo'):\n",
    "        super(ROC_AUC_Score, self).__init__()\n",
    "        self.num_classes = config.n_classes\n",
    "        self.average = average\n",
    "        self.multi_class = multi_class  # 'ovo' (one-vs-one) or 'ovr' (one-vs-rest)\n",
    "        self.label_ids = np.arange(self.num_classes)\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # logits: (batch_size, n_classes)\n",
    "        # targets: (batch_size,) with integer labels\n",
    "        \n",
    "        # Apply softmax to convert logits to probabilities\n",
    "        probas = torch.exp(F.log_softmax(logits, dim=1))\n",
    "\n",
    "        # Detach and move to CPU for sklearn compatibility\n",
    "        probas = probas.detach().cpu().numpy()\n",
    "        targets = targets.detach().cpu().numpy()\n",
    "        \n",
    "        df_scores = pd.DataFrame(probas, columns=self.label_ids)\n",
    "        df_scores['target'] = targets\n",
    "        \n",
    "        # remove samples with classes which is predeicted as 0 in all samples\n",
    "        unscored_cols = df_scores.columns[df_scores.sum(axis=0) == 0]\n",
    "        rows_to_remove = df_scores['target'].isin(unscored_cols)\n",
    "        df_scores = df_scores[~rows_to_remove]\n",
    "        \n",
    "        eval_score = roc_auc_score(\n",
    "            y_true=df_scores['target'].values,\n",
    "            y_score=df_scores[self.label_ids].values,\n",
    "            average=self.average, \n",
    "            multi_class=self.multi_class,\n",
    "            labels=self.label_ids\n",
    "        )\n",
    "        \n",
    "        return eval_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test loss_fn and eval_fn\n",
    "# loss_fn = FocalLoss(gamma=2, alpha=class_weights.values, reduction='mean', device='cpu')\n",
    "# eval_fn = ROC_AUC_Score(config, average='macro', multi_class='ovo')\n",
    "\n",
    "# # target_labels = torch.tensor(df_audio_meta['species_id'].sample(10).values)\n",
    "# target_labels = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "# print('Target Labels:', target_labels, \"\\n\")\n",
    "\n",
    "# Test 1: perfect prediction\n",
    "# logits_perfect = F.one_hot(target_labels, num_classes=config.n_classes).float() * 100\n",
    "# loss_perfect = loss_fn(logits_perfect, target_labels)\n",
    "\n",
    "# eval_score_perfect = eval_fn(logits_perfect, target_labels)\n",
    "# print(f\"Perfect Prediction: Loss: {loss_perfect.item()}, Eval Score: {eval_score_perfect}\")\n",
    "# print(\" \")\n",
    "\n",
    "# Test 2: half correct\n",
    "# half_correct = target_labels.clone()\n",
    "# half_correct[:5] = (half_correct[:5] + 1) % config.n_classes  \n",
    "# logits_half = F.one_hot(half_correct, num_classes=config.n_classes).float() * 100\n",
    "# logits_half[:5] *= -1  \n",
    "# loss_half = loss_fn(logits_half, target_labels)\n",
    "\n",
    "# eval_score_half = eval_fn(logits_half, target_labels)\n",
    "# print(f\"Half Correct Prediction: Loss: {loss_half.item()}, Eval Score: {eval_score_half}\")\n",
    "# print(\" \")\n",
    "\n",
    "# Test 3: random prediction\n",
    "# logits_random = torch.rand((10, config.n_classes))\n",
    "# loss_random = loss_fn(logits_random, target_labels)\n",
    "\n",
    "# eval_score_random = eval_fn(logits_random, target_labels)\n",
    "# print(f\"Random Prediction: Loss: {loss_random.item()}, Eval Score: {eval_score_random}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdAST(nn.Module):\n",
    "    \n",
    "    def __init__(self, backbone_name, n_classes, n_mlp_layers=1, activation='silu'):\n",
    "        super(BirdAST, self).__init__()\n",
    "        \n",
    "        # pre-trained backbone\n",
    "        backbone_config = ASTConfig.from_pretrained(backbone_name)\n",
    "        self.ast = ASTModel.from_pretrained(backbone_name, config=backbone_config)\n",
    "        self.hidden_size = backbone_config.hidden_size\n",
    "        \n",
    "        # set activation functions\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'silu':\n",
    "            self.activation = nn.SiLU()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function. Choose 'relu' or 'silu'.\")\n",
    "        \n",
    "        # define MLP layers with activation\n",
    "        layers = []\n",
    "        for _ in range(n_mlp_layers):\n",
    "            layers.append(nn.Linear(self.hidden_size, self.hidden_size))\n",
    "            layers.append(self.activation)\n",
    "        layers.append(nn.Linear(self.hidden_size, n_classes))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, spectrogram):\n",
    "        # spectrogram: (batch_size, n_mels, n_frames)\n",
    "        # output: (batch_size, n_classes)\n",
    "        \n",
    "        ast_output = self.ast(spectrogram, output_hidden_states=False)\n",
    "        logits = self.mlp(ast_output.last_hidden_state[:, 0, :]) # Use the CLS token \n",
    "        \n",
    "        return {'logits': logits}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test the model / loss_fn / eval_fn using dataloader\n",
    "\n",
    "# bs_dataset = BirdSongDataset(df_audio_meta, config)\n",
    "# bs_dataloader = DataLoader(bs_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# loss_fn = FocalLoss(gamma=2, alpha=class_weights.values, reduction='mean', device='cpu')\n",
    "# eval_fn = ROC_AUC_Score(label_ids_list, average='macro')\n",
    "\n",
    "# bird_ast_model = BirdAST(config.backbone_name, config.n_classes, n_mlp_layers=1, activation='silu')\n",
    "\n",
    "# for batch in bs_dataloader:\n",
    "    \n",
    "#     input_ids = batch['input_ids']\n",
    "#     labels = batch['labels']\n",
    "    \n",
    "#     output = bird_ast_model(input_ids)\n",
    "#     logits = output['logits']\n",
    "    \n",
    "#     loss = loss_fn(logits, labels)\n",
    "#     eval_score = eval_fn(logits, labels)\n",
    "    \n",
    "#     print(f\"Shape of input_ids: {input_ids.shape}\")\n",
    "#     print(f\"Shape of labels: {labels.shape}\")\n",
    "#     print(f\"Shape of logits: {logits.shape}\")\n",
    "#     print(f\"Loss: {loss.item()}, Eval Score: {eval_score}\")\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.value = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.value = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "        \n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self, model, loss_fn, evel_fn, logger, config, is_higher_better=True):\n",
    "        '''\n",
    "        model: nn.Module\n",
    "        loss_fn: loss function\n",
    "        evel_fn: evaluation function\n",
    "        logger: logger\n",
    "        config: Config\n",
    "        is_higher_better: bool (default: True) whether higher evaluation score is better\n",
    "        '''\n",
    "\n",
    "        self.model = model\n",
    "        self.logger = logger\n",
    "        self.config = config\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.loss_fn = loss_fn\n",
    "        self.loss_fn.to(self.device)\n",
    "        \n",
    "        self.eval_fn = evel_fn\n",
    "        self.is_higher_better = is_higher_better\n",
    "        \n",
    "    def train(self, train_loader, valid_loader, print_epoch_freq=50, from_checkpoint=None, use_tqdm=True):\n",
    "\n",
    "        self.optimizer = AdamW(self.model.parameters(), lr=1e-3, weight_decay=self.config.weight_decay)\n",
    "\n",
    "        self.scheduler = OneCycleLR(\n",
    "            self.optimizer,\n",
    "            max_lr=self.config.max_lr,\n",
    "            epochs=self.config.epochs,\n",
    "            steps_per_epoch=len(train_loader),\n",
    "            pct_start=0.1,\n",
    "            anneal_strategy=\"cos\",\n",
    "            final_div_factor=self.config.lr_final_div,\n",
    "        )\n",
    "\n",
    "        if from_checkpoint is not None:\n",
    "            self.model.load_state_dict(torch.load(from_checkpoint, map_location=self.device))\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        best_weights, best_preds, best_loss = None, None, float(\"-inf\") if self.is_higher_better else float(\"inf\")\n",
    "        loss_records = {\"train\": [], \"valid\": []}\n",
    "        \n",
    "        if use_tqdm:\n",
    "            pbar = tqdm(range(self.config.epochs), total=self.config.epochs, unit=\"epoch\", leave=True, desc=\"Training Progress\")\n",
    "        else:\n",
    "            pbar = range(self.config.epochs)\n",
    "            \n",
    "        for epoch in pbar:\n",
    "            start_epoch = time()\n",
    "\n",
    "            train_loss, _ = self._train_or_valid_epoch(epoch, train_loader, is_train=True, use_tqdm=use_tqdm)\n",
    "            valid_loss, valid_preds = self._train_or_valid_epoch(epoch, valid_loader, is_train=False, use_tqdm=use_tqdm)\n",
    "            \n",
    "            loss_records[\"train\"].append(train_loss)\n",
    "            loss_records[\"valid\"].append(valid_loss)\n",
    "\n",
    "            elapsed = time() - start_epoch\n",
    "            \n",
    "            if (epoch % print_epoch_freq == 0) or (epoch == (self.config.epochs - 1)):\n",
    "                self.logger.info(f\"Epoch {epoch + 1} - Train Loss: {train_loss:.4f} - Valid Loss: {valid_loss:.4f} - Elapsed Time: {elapsed:.2f}s\")\n",
    "            \n",
    "            if self.is_higher_better:\n",
    "                if valid_loss > best_loss:\n",
    "                    best_loss = valid_loss\n",
    "                    best_weights = self.model.state_dict()\n",
    "                    best_preds = valid_preds\n",
    "                    self.logger.info(f\"- Epoch {epoch + 1}: Best model found with loss = {best_loss:.4f}.\")\n",
    "            else:\n",
    "                if valid_loss < best_loss:\n",
    "                    best_loss = valid_loss\n",
    "                    best_weights = self.model.state_dict()\n",
    "                    best_preds = valid_preds\n",
    "                    self.logger.info(f\"- Epoch {epoch + 1}: Best model found with loss = {best_loss:.4f}.\")\n",
    "\n",
    "        return best_weights, best_preds, loss_records\n",
    "\n",
    "    def _train_or_valid_epoch(self, epoch_id, dataloader, is_train=True, use_tqdm=True):\n",
    "\n",
    "        self.model.train() if is_train else self.model.eval()\n",
    "        mode = \"Train\" if is_train else \"Valid\"\n",
    "\n",
    "        len_loader = len(dataloader)\n",
    "        scaler = GradScaler(enabled=self.config.amp)\n",
    "        loss_meter = AverageMeter()\n",
    "        labels_record, predicts_record = [], []\n",
    "\n",
    "        start = time()\n",
    "        \n",
    "        if use_tqdm:\n",
    "            pbar = tqdm(enumerate(dataloader), total=len_loader, desc=mode, unit=\"batch\")\n",
    "        else:\n",
    "            pbar = enumerate(dataloader)\n",
    "            \n",
    "        for step, data_dict in pbar:\n",
    "            \n",
    "            input_ids = data_dict['input_ids'].to(self.device)\n",
    "            labels = data_dict['labels'].to(self.device)\n",
    "            \n",
    "            if is_train:\n",
    "                with autocast(enabled=self.config.amp):\n",
    "                    model_output = self.model(input_ids)\n",
    "                    logits = model_output['logits']\n",
    "                    train_loss = self.loss_fn(logits, labels)\n",
    "                    \n",
    "                if self.config.grad_accum_steps > 1:\n",
    "                    train_loss = train_loss / self.config.grad_accum_steps\n",
    "                    \n",
    "                scaler.scale(train_loss).backward()\n",
    "                grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.max_grad_norm)\n",
    "                if (step + 1) % self.config.grad_accum_steps == 0:\n",
    "                    scaler.step(self.optimizer)\n",
    "                    scaler.update()\n",
    "                    self.optimizer.zero_grad()\n",
    "                    self.scheduler.step()\n",
    "                    \n",
    "                loss_meter.update(train_loss.item())\n",
    "                \n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    model_output = self.model(input_ids)\n",
    "                    logits = model_output['logits']\n",
    "                    valid_loss = self.loss_fn(logits, labels)\n",
    "\n",
    "                if self.config.grad_accum_steps > 1:\n",
    "                    valid_loss = valid_loss / self.config.grad_accum_steps\n",
    "                    \n",
    "                loss_meter.update(valid_loss.item())\n",
    "                \n",
    "                predicts_record.append(logits)\n",
    "                labels_record.append(labels)\n",
    "            \n",
    "            end = time()\n",
    "            \n",
    "            if self.config.print_freq:\n",
    "                if (step % self.config.print_freq == 0) or (step == (len_loader - 1)):\n",
    "                    lr = self.scheduler.get_last_lr()[0]\n",
    "                    info = f\"Epoch {epoch_id + 1} [{step}/{len_loader}] | {mode} \"\n",
    "                    \n",
    "                    if is_train:\n",
    "                        info += f\"Loss: {loss_meter.avg:.4f} Grad: {grad_norm:.4f} LR: {lr:.4e}\"\n",
    "                    else:\n",
    "                        info += f\"Loss: {loss_meter.avg:.4f}\"\n",
    "\n",
    "                    info += f\" | Elapse: {end - start:.2f}s\"\n",
    "                    self.logger.info(info)\n",
    "\n",
    "        if is_train:\n",
    "            wandb.log({\n",
    "                \"Train Loss\": loss_meter.avg, \n",
    "                \"Learning Rate\": self.scheduler.get_last_lr()[0],\n",
    "                \"Gradient Norm\": grad_norm,\n",
    "                \"Epoch\": epoch_id + 1\n",
    "            })\n",
    "            return loss_meter.avg, None\n",
    "        else:\n",
    "            eval_loss = self.eval_fn(\n",
    "                torch.cat(predicts_record).cpu(),\n",
    "                torch.cat(labels_record).cpu()\n",
    "                )\n",
    "            wandb.log({\n",
    "                \"Valid Loss\": loss_meter.avg,\n",
    "                \"Eval Score\": eval_loss,\n",
    "                \"Epoch\": epoch_id + 1\n",
    "            })\n",
    "            predicts_record = np.concatenate([p.cpu().detach().numpy() for p in predicts_record], axis=0)\n",
    "            return eval_loss, predicts_record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_record(loss_history, final_loss, start_at=0, save_to=None):\n",
    "    \n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(8, 4))\n",
    "    ax2 = ax1.twinx()\n",
    "    for i, loss in enumerate(loss_history):\n",
    "        ax1.plot(np.arange(start_at, len(loss['train'])), loss['train'][start_at:], \"-\",   label=f'Train_{i}')\n",
    "        ax2.plot(np.arange(start_at, len(loss['valid'])), loss['valid'][start_at:], \".--\", label=f'Valid_{i}')\n",
    "        \n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Train Loss\")\n",
    "    ax2.set_ylabel(\"Valid Loss (Dashed)\")\n",
    "    ax1.set_title(f\"Final Eval-Loss: {final_loss:.4f}\")\n",
    "    ax1.legend(loc='lower left', bbox_to_anchor=[1.15, 0])\n",
    "    ax2.legend(loc='upper left', bbox_to_anchor=[1.15, 1])\n",
    "    \n",
    "    if save_to:\n",
    "        plt.savefig(save_to)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=config.n_splits)\n",
    "df_audio_meta['fold'] = 0\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(gkf.split(df_audio_meta, groups=df_audio_meta['group_id'])):\n",
    "    df_audio_meta.loc[test_index, 'fold'] = fold\n",
    "    \n",
    "display(df_audio_meta['fold'].value_counts())\n",
    "\n",
    "# check if any sample in valid set has the same mp3_link as the train set\n",
    "for fold in range(config.n_splits):\n",
    "    train_group_ids = df_audio_meta[df_audio_meta['fold'] != fold]['mp3_link'].unique()\n",
    "    valid_group_ids = df_audio_meta[df_audio_meta['fold'] == fold]['mp3_link'].unique()\n",
    "    common_groups = set(train_group_ids).intersection(set(valid_group_ids))\n",
    "    print(f\"Fold {fold}: Number of common groups between train and valid: {len(common_groups)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = FocalLoss(gamma=2, alpha=class_weights.values, reduction='mean', device='cpu')\n",
    "eval_fn = ROC_AUC_Score(config, average='macro', multi_class='ovo')\n",
    "\n",
    "oof, loss_history = pd.DataFrame(), []\n",
    "\n",
    "logger = get_logger(log_file=f\"{config.log_dir}/{config.model_name}_training.log\")\n",
    "\n",
    "# log TRAIN_CONFIG\n",
    "logger.info(f\"{'#'*35} TRAIN_CONFIG {'#'*35}\")\n",
    "for k, v in config.__dict__.items():\n",
    "    if '__' not in k:\n",
    "        logger.info(f\"{k}: {v}\")\n",
    "\n",
    "logger.info(f\"{'#'*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Training Loop Starts Here\n",
    "# --------------------------------------------------------------\n",
    "loader_kwargs = {\n",
    "    \"batch_size\": config.batch_size,\n",
    "    \"num_workers\": config.num_workers,\n",
    "    \"pin_memory\": True,\n",
    "    \"shuffle\": False,\n",
    "    'collate_fn': collate_fn\n",
    "}\n",
    "\n",
    "prediction_columns = [f\"pred_{i}\" for i in range(config.n_classes)]\n",
    "    \n",
    "for fold_id in range(0, config.n_splits):\n",
    "    tik = time()\n",
    "    \n",
    "    wandb_init(project_name=config.model_name, run_name=f\"fold_{fold_id}\", config=config)\n",
    "    \n",
    "    train_df = df_audio_meta[df_audio_meta['fold'] != fold_id].copy().reset_index(drop=True)\n",
    "    valid_df = df_audio_meta[df_audio_meta['fold'] == fold_id].copy().reset_index(drop=True)\n",
    "    \n",
    "    train_folds = BirdSongDataset(train_df, config)\n",
    "    valid_folds = BirdSongDataset(valid_df, config)\n",
    "    \n",
    "    train_loader = DataLoader(train_folds, **loader_kwargs)\n",
    "    valid_loader = DataLoader(valid_folds, **loader_kwargs)\n",
    "        \n",
    "    model = BirdAST(config.backbone_name, config.n_classes, n_mlp_layers=1, activation='silu')\n",
    "    \n",
    "    trainer = Trainer(model, loss_fn, eval_fn, logger, config, is_higher_better=True)\n",
    "    \n",
    "    best_weights, best_preds, loss_records = trainer.train( \n",
    "        train_loader, \n",
    "        valid_loader, \n",
    "        print_epoch_freq=config.print_epoch_freq,\n",
    "        from_checkpoint=None,\n",
    "        use_tqdm=True\n",
    "        )\n",
    "    \n",
    "    loss_history.append(loss_records)\n",
    "    \n",
    "    df_valid = pd.DataFrame({'species_id': valid_df['species_id'], 'fold': fold})\n",
    "    df_valid[prediction_columns] = best_preds\n",
    "    \n",
    "    oof = pd.concat([oof, df_valid], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    save_model_name = f\"{config.model_name}_fold_{fold_id}\"\n",
    "    torch.save(best_weights, f\"{config.log_dir}/{save_model_name}.pth\")\n",
    "\n",
    "    del train_folds, valid_folds, train_loader, valid_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    valid_loss_fold = eval_fn(\n",
    "        torch.tensor(oof[prediction_columns].values),\n",
    "        torch.tensor(oof['species_id'].values)\n",
    "    )\n",
    "    logger.info(f\"Fold {fold_id} | Time: {(time() - tik)/60:.2f}min | Overall Evaluation Loss: {valid_loss_fold:.4f}\")\n",
    "    \n",
    "    # Save the oof predictions\n",
    "    oof.to_csv(f\"{config.log_dir}/{config.model_name}_oof.csv\", index=False)\n",
    "    \n",
    "    wandb.finish()\n",
    "        \n",
    "# Summarize the final results\n",
    "valid_loss = eval_fn(\n",
    "    torch.tensor(oof[prediction_columns].values),\n",
    "    torch.tensor(oof['species_id'].values)\n",
    ")\n",
    "\n",
    "plot_loss_record(loss_history, valid_loss, start_at=0, save_to=os.path.join(config.log_dir, f\"{config.model_name}_loss.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a hidden layer of the model\n",
    "\n",
    "model = BirdAST(config.backbone_name, config.n_classes, n_mlp_layers=1, activation='silu')\n",
    "model.load_state_dict(torch.load(f\"{config.log_dir}/{config.model_name}_fold_0.pth\"))\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "sample_dataset = BirdSongDataset(df_audio_meta, config)\n",
    "sample_dataloader = DataLoader(sample_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "for batch in sample_dataloader:\n",
    "    \n",
    "    input_ids = batch['input_ids'].to(DEVICE)\n",
    "    labels = batch['labels'].to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_output = model(input_ids)\n",
    "        logits = model_output['logits']\n",
    "        hidden_states = model.ast(input_ids, output_hidden_states=True) #['hidden_states']\n",
    "        \n",
    "    break\n",
    "\n",
    "last_hidden_state = hidden_states.last_hidden_state.cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 6))\n",
    "\n",
    "ax = axes[0]\n",
    "im = ax.imshow(last_hidden_state[0].T, aspect='auto', origin='lower', cmap='plasma') #, vmin=-1, vmax=1)\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "\n",
    "ax = axes[1]\n",
    "arr = last_hidden_state[0].T\n",
    "ax.plot(arr.max(axis=0), label='Mean')\n",
    "# ax.plot(arr[3], label='First')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse training log\n",
    "import re \n",
    "\n",
    "log_file = f\"{config.log_dir}/{config.model_name}_training.log\"\n",
    "\n",
    "with open(log_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "epoch_records = []\n",
    "epoch_pattern = re.compile(r\"Epoch (\\d+) - Train Loss: (\\d+\\.\\d+) - Valid Loss: (\\d+\\.\\d+) - Elapsed Time: (\\d+\\.\\d+)s\")\n",
    "\n",
    "for line in lines:\n",
    "    \n",
    "    try:\n",
    "        epoch, train_loss, valid_loss, elapsed = epoch_pattern.findall(line)[0]\n",
    "        epoch_records.append({\n",
    "            \"epoch\": int(epoch),\n",
    "            \"train_loss\": float(train_loss),\n",
    "            \"valid_loss\": float(valid_loss),\n",
    "            \"elapsed\": float(elapsed)\n",
    "        })\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "df_epoch_records = pd.DataFrame(epoch_records)\n",
    "\n",
    "df_epoch_records['fold_id'] = df_epoch_records.index // 5\n",
    "\n",
    "df_epoch_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_719</th>\n",
       "      <th>pred_720</th>\n",
       "      <th>pred_721</th>\n",
       "      <th>pred_722</th>\n",
       "      <th>pred_723</th>\n",
       "      <th>pred_724</th>\n",
       "      <th>pred_725</th>\n",
       "      <th>pred_726</th>\n",
       "      <th>pred_727</th>\n",
       "      <th>species_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>329</td>\n",
       "      <td>4</td>\n",
       "      <td>0.571484</td>\n",
       "      <td>-1.303516</td>\n",
       "      <td>-1.316874</td>\n",
       "      <td>-0.502493</td>\n",
       "      <td>-1.238950</td>\n",
       "      <td>-2.716704</td>\n",
       "      <td>-0.045544</td>\n",
       "      <td>-0.585232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053766</td>\n",
       "      <td>-2.868916</td>\n",
       "      <td>-0.192756</td>\n",
       "      <td>-1.407187</td>\n",
       "      <td>-1.308793</td>\n",
       "      <td>-0.344398</td>\n",
       "      <td>-0.880000</td>\n",
       "      <td>-0.776647</td>\n",
       "      <td>-1.018193</td>\n",
       "      <td>0-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>329</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.099693</td>\n",
       "      <td>-1.248484</td>\n",
       "      <td>-1.453659</td>\n",
       "      <td>-0.496415</td>\n",
       "      <td>-1.360897</td>\n",
       "      <td>-2.603964</td>\n",
       "      <td>-0.122749</td>\n",
       "      <td>-0.046868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270880</td>\n",
       "      <td>-2.929474</td>\n",
       "      <td>-0.536227</td>\n",
       "      <td>-1.472482</td>\n",
       "      <td>-1.463723</td>\n",
       "      <td>-0.141152</td>\n",
       "      <td>-0.713918</td>\n",
       "      <td>-1.013981</td>\n",
       "      <td>-0.768844</td>\n",
       "      <td>0-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "      <td>0.373392</td>\n",
       "      <td>-0.352611</td>\n",
       "      <td>-0.725645</td>\n",
       "      <td>0.461556</td>\n",
       "      <td>-1.506253</td>\n",
       "      <td>-1.697448</td>\n",
       "      <td>-1.994810</td>\n",
       "      <td>-0.025809</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052105</td>\n",
       "      <td>-2.488384</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>-1.161093</td>\n",
       "      <td>-1.508877</td>\n",
       "      <td>-0.133160</td>\n",
       "      <td>0.016762</td>\n",
       "      <td>-2.439859</td>\n",
       "      <td>0.312477</td>\n",
       "      <td>0-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262</td>\n",
       "      <td>4</td>\n",
       "      <td>0.504005</td>\n",
       "      <td>-1.078642</td>\n",
       "      <td>-0.618699</td>\n",
       "      <td>-0.928933</td>\n",
       "      <td>-1.732492</td>\n",
       "      <td>-1.812730</td>\n",
       "      <td>-0.015532</td>\n",
       "      <td>0.359620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.900635</td>\n",
       "      <td>-1.451020</td>\n",
       "      <td>0.094821</td>\n",
       "      <td>-0.657967</td>\n",
       "      <td>-1.167834</td>\n",
       "      <td>-0.829126</td>\n",
       "      <td>-0.654593</td>\n",
       "      <td>-0.373018</td>\n",
       "      <td>-0.516711</td>\n",
       "      <td>0-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262</td>\n",
       "      <td>4</td>\n",
       "      <td>0.438048</td>\n",
       "      <td>-0.330164</td>\n",
       "      <td>-1.086372</td>\n",
       "      <td>-1.164569</td>\n",
       "      <td>-1.850764</td>\n",
       "      <td>-1.863517</td>\n",
       "      <td>-0.297522</td>\n",
       "      <td>0.561704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218926</td>\n",
       "      <td>-1.826046</td>\n",
       "      <td>-0.198279</td>\n",
       "      <td>-1.135705</td>\n",
       "      <td>-0.970447</td>\n",
       "      <td>-1.266783</td>\n",
       "      <td>0.050430</td>\n",
       "      <td>-0.213947</td>\n",
       "      <td>-0.561578</td>\n",
       "      <td>0-50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  731 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   species_id  fold    pred_0    pred_1    pred_2    pred_3    pred_4  \\\n",
       "0         329     4  0.571484 -1.303516 -1.316874 -0.502493 -1.238950   \n",
       "1         329     4 -0.099693 -1.248484 -1.453659 -0.496415 -1.360897   \n",
       "2          94     4  0.373392 -0.352611 -0.725645  0.461556 -1.506253   \n",
       "3         262     4  0.504005 -1.078642 -0.618699 -0.928933 -1.732492   \n",
       "4         262     4  0.438048 -0.330164 -1.086372 -1.164569 -1.850764   \n",
       "\n",
       "     pred_5    pred_6    pred_7  ...  pred_719  pred_720  pred_721  pred_722  \\\n",
       "0 -2.716704 -0.045544 -0.585232  ...  0.053766 -2.868916 -0.192756 -1.407187   \n",
       "1 -2.603964 -0.122749 -0.046868  ...  0.270880 -2.929474 -0.536227 -1.472482   \n",
       "2 -1.697448 -1.994810 -0.025809  ... -0.052105 -2.488384  0.007961 -1.161093   \n",
       "3 -1.812730 -0.015532  0.359620  ...  0.900635 -1.451020  0.094821 -0.657967   \n",
       "4 -1.863517 -0.297522  0.561704  ...  0.218926 -1.826046 -0.198279 -1.135705   \n",
       "\n",
       "   pred_723  pred_724  pred_725  pred_726  pred_727  species_category  \n",
       "0 -1.308793 -0.344398 -0.880000 -0.776647 -1.018193              0-50  \n",
       "1 -1.463723 -0.141152 -0.713918 -1.013981 -0.768844              0-50  \n",
       "2 -1.508877 -0.133160  0.016762 -2.439859  0.312477              0-50  \n",
       "3 -1.167834 -0.829126 -0.654593 -0.373018 -0.516711              0-50  \n",
       "4 -0.970447 -1.266783  0.050430 -0.213947 -0.561578              0-50  \n",
       "\n",
       "[5 rows x 731 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# analyze oof predictions\n",
    "df_oof = pd.read_csv(f\"{config.log_dir}/{config.model_name}_oof.csv\")\n",
    "df_oof['species_id'] = df_oof['species_id'].astype(int)\n",
    "\n",
    "species_category = pd.cut(\n",
    "    df_oof['species_id'].value_counts(), \n",
    "    bins=[0, 50, 120], \n",
    "    labels=['0-50', '50-120']\n",
    "    ).to_frame()\n",
    "\n",
    "species_category['count']\n",
    "\n",
    "df_oof['species_category'] = df_oof['species_id'].map({i: c for i, c in enumerate(species_category['count'])})\n",
    "\n",
    "prediction_columns = [f\"pred_{i}\" for i in range(config.n_classes)]\n",
    "\n",
    "display(df_oof.head())\n",
    "\n",
    "# eval_fn = ROC_AUC_Score(config, average='macro', multi_class='ovo')\n",
    "\n",
    "# # caculate the overall evaluation loss\n",
    "# eval_loss = eval_fn(\n",
    "#     torch.tensor(df_oof[prediction_columns].values),\n",
    "#     torch.tensor(df_oof['species_id'].values)\n",
    "# )\n",
    "\n",
    "# print(f\"Overall Evaluation Loss: {eval_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species_id</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_719</th>\n",
       "      <th>pred_720</th>\n",
       "      <th>pred_721</th>\n",
       "      <th>pred_722</th>\n",
       "      <th>pred_723</th>\n",
       "      <th>pred_724</th>\n",
       "      <th>pred_725</th>\n",
       "      <th>pred_726</th>\n",
       "      <th>pred_727</th>\n",
       "      <th>species_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>440</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.410160</td>\n",
       "      <td>0.414931</td>\n",
       "      <td>-0.764270</td>\n",
       "      <td>-0.334999</td>\n",
       "      <td>-2.082050</td>\n",
       "      <td>-1.523369</td>\n",
       "      <td>-0.176110</td>\n",
       "      <td>-0.423524</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.305855</td>\n",
       "      <td>-2.798390</td>\n",
       "      <td>-0.449429</td>\n",
       "      <td>-0.888111</td>\n",
       "      <td>-1.792285</td>\n",
       "      <td>-2.879189</td>\n",
       "      <td>-0.537833</td>\n",
       "      <td>-1.758069</td>\n",
       "      <td>-0.868848</td>\n",
       "      <td>0-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7543</th>\n",
       "      <td>440</td>\n",
       "      <td>4</td>\n",
       "      <td>0.694210</td>\n",
       "      <td>-0.940783</td>\n",
       "      <td>-0.651027</td>\n",
       "      <td>-1.255976</td>\n",
       "      <td>-1.528125</td>\n",
       "      <td>-2.158752</td>\n",
       "      <td>-0.323124</td>\n",
       "      <td>-0.340748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382929</td>\n",
       "      <td>-2.528863</td>\n",
       "      <td>-0.900308</td>\n",
       "      <td>-0.599194</td>\n",
       "      <td>-1.318963</td>\n",
       "      <td>-0.960416</td>\n",
       "      <td>-0.889694</td>\n",
       "      <td>-1.999388</td>\n",
       "      <td>-3.240913</td>\n",
       "      <td>0-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9830</th>\n",
       "      <td>440</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.967315</td>\n",
       "      <td>-0.588008</td>\n",
       "      <td>-0.869392</td>\n",
       "      <td>-2.098948</td>\n",
       "      <td>-1.743395</td>\n",
       "      <td>-1.648687</td>\n",
       "      <td>-3.191589</td>\n",
       "      <td>0.997326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154881</td>\n",
       "      <td>-1.817728</td>\n",
       "      <td>-0.795427</td>\n",
       "      <td>-0.411474</td>\n",
       "      <td>-1.355877</td>\n",
       "      <td>-0.634266</td>\n",
       "      <td>-1.261839</td>\n",
       "      <td>-2.034698</td>\n",
       "      <td>-0.074583</td>\n",
       "      <td>0-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9831</th>\n",
       "      <td>440</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.691131</td>\n",
       "      <td>-0.425343</td>\n",
       "      <td>-0.622502</td>\n",
       "      <td>-2.392962</td>\n",
       "      <td>-1.377782</td>\n",
       "      <td>-1.983776</td>\n",
       "      <td>-3.198071</td>\n",
       "      <td>0.907449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090377</td>\n",
       "      <td>-2.188928</td>\n",
       "      <td>-0.880146</td>\n",
       "      <td>-0.358666</td>\n",
       "      <td>-1.692788</td>\n",
       "      <td>-0.906389</td>\n",
       "      <td>-1.049707</td>\n",
       "      <td>-2.128478</td>\n",
       "      <td>-0.015938</td>\n",
       "      <td>0-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9832</th>\n",
       "      <td>440</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.566546</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>-1.088739</td>\n",
       "      <td>-2.689743</td>\n",
       "      <td>-1.778816</td>\n",
       "      <td>-1.786288</td>\n",
       "      <td>-2.921161</td>\n",
       "      <td>0.673203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182716</td>\n",
       "      <td>-1.971469</td>\n",
       "      <td>-0.610165</td>\n",
       "      <td>-1.006683</td>\n",
       "      <td>-1.557320</td>\n",
       "      <td>-0.809824</td>\n",
       "      <td>-1.084950</td>\n",
       "      <td>-2.153754</td>\n",
       "      <td>-0.238671</td>\n",
       "      <td>0-50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  731 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      species_id  fold    pred_0    pred_1    pred_2    pred_3    pred_4  \\\n",
       "5145         440     4 -0.410160  0.414931 -0.764270 -0.334999 -2.082050   \n",
       "7543         440     4  0.694210 -0.940783 -0.651027 -1.255976 -1.528125   \n",
       "9830         440     4 -1.967315 -0.588008 -0.869392 -2.098948 -1.743395   \n",
       "9831         440     4 -2.691131 -0.425343 -0.622502 -2.392962 -1.377782   \n",
       "9832         440     4 -2.566546  0.017373 -1.088739 -2.689743 -1.778816   \n",
       "\n",
       "        pred_5    pred_6    pred_7  ...  pred_719  pred_720  pred_721  \\\n",
       "5145 -1.523369 -0.176110 -0.423524  ... -1.305855 -2.798390 -0.449429   \n",
       "7543 -2.158752 -0.323124 -0.340748  ...  0.382929 -2.528863 -0.900308   \n",
       "9830 -1.648687 -3.191589  0.997326  ...  0.154881 -1.817728 -0.795427   \n",
       "9831 -1.983776 -3.198071  0.907449  ...  0.090377 -2.188928 -0.880146   \n",
       "9832 -1.786288 -2.921161  0.673203  ...  0.182716 -1.971469 -0.610165   \n",
       "\n",
       "      pred_722  pred_723  pred_724  pred_725  pred_726  pred_727  \\\n",
       "5145 -0.888111 -1.792285 -2.879189 -0.537833 -1.758069 -0.868848   \n",
       "7543 -0.599194 -1.318963 -0.960416 -0.889694 -1.999388 -3.240913   \n",
       "9830 -0.411474 -1.355877 -0.634266 -1.261839 -2.034698 -0.074583   \n",
       "9831 -0.358666 -1.692788 -0.906389 -1.049707 -2.128478 -0.015938   \n",
       "9832 -1.006683 -1.557320 -0.809824 -1.084950 -2.153754 -0.238671   \n",
       "\n",
       "      species_category  \n",
       "5145              0-50  \n",
       "7543              0-50  \n",
       "9830              0-50  \n",
       "9831              0-50  \n",
       "9832              0-50  \n",
       "\n",
       "[5 rows x 731 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oof[df_oof['species_id'] == 440].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make cm plots\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, save_to=None):\n",
    "    \n",
    "    sns.set(rc={'axes.facecolor':'white', 'figure.facecolor':'white'}) #f3ede2\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=False, cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    # plt.xticks([])\n",
    "    # plt.yticks([])\n",
    "    plt.title(\"Normalized Confusion Matrix\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if save_to:\n",
    "        plt.savefig(save_to)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "y_true = df_oof['species_id'].values\n",
    "y_pred = df_oof[prediction_columns].values.argmax(axis=1)\n",
    "\n",
    "labels = df_oof['species_id'].unique()\n",
    "labels.sort()\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    y_true, y_pred, \n",
    "    labels=labels,\n",
    "    save_to=os.path.join(config.log_dir, f\"{config.model_name}_cm.jpg\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77545/1933831211.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  cm = cm / cm.sum(axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = np.random.choice(len(df_oof['species_id'].unique()), 15)\n",
    "labels.sort()\n",
    "\n",
    "tmp = df_oof[df_oof['species_id'].isin(labels)].copy()\n",
    "# plot confusion matrix\n",
    "y_true = tmp['species_id'].values\n",
    "y_pred = tmp[prediction_columns].values.argmax(axis=1)\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred, labels=labels, save_to=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc F1, Precision, Recall, mAP \n",
    "from sklearn.metrics import f1_score, precision_score, recall_score \n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(species_category['count'].unique())\n",
    "\n",
    "for category_id in ['0-50', '50-120']:\n",
    "    tmp = df_oof[df_oof['species_category'] == category_id].copy().reset_index(drop=True)\n",
    "\n",
    "    y_true = tmp['species_id'].values\n",
    "    y_pred = tmp[prediction_columns].values.argmax(axis=1)\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    print(f\"Category: {category_id} | N_samples: {len(tmp)} | N_classes: {tmp['species_id'].nunique()} | F1: {f1} | Precision: {precision} | Recall: {recall:.4f}\")\n",
    "\n",
    "    # labels = tmp['species_id'].unique()\n",
    "    # cm = confusion_matrix(y_true, y_pred, labels=labels, normalize='pred')\n",
    "    \n",
    "    # plt.figure(figsize=(10, 10))\n",
    "    # sns.heatmap(cm, annot=False, cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "    # plt.xlabel(\"Predicted Label\")\n",
    "    # plt.ylabel(\"True Label\")\n",
    "    # plt.title(\"Normalized Confusion Matrix | Category: \" + category_id)\n",
    "    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot training progress\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(9, 6))\n",
    "\n",
    "# ax_right = ax.twinx()\n",
    "\n",
    "# for fold_id in range(config.n_splits):\n",
    "#     df_fold = df_epoch_records[df_epoch_records['fold_id'] == fold_id]\n",
    "#     ax.plot(df_fold['epoch'], df_fold['train_loss'], marker='o', label=f\"Train_Fold_{fold_id}\")\n",
    "#     ax_right.plot(df_fold['epoch'], df_fold['valid_loss'], linestyle=\"--\", marker='*', label=f\"Valid_Fold_{fold_id}\")\n",
    "\n",
    "# ax.set_xticks(np.arange(0, config.epochs, 1)+1)\n",
    "# ax.set_xlabel(\"Epoch\", fontsize=14, fontfamily='serif')\n",
    "# ax.set_ylabel(\"Training Loss (Focal Loss)\", fontsize=14, fontfamily='serif')\n",
    "# ax.set_title(f\"Training Progress | Overall ROCAUC: {eval_loss:.3f}\", fontsize=18, fontfamily='serif')\n",
    "# ax.legend(loc='upper left')\n",
    "\n",
    "# ax_right.set_ylabel(\"Validation Loss (ROCAUC)\", fontsize=14, fontfamily='serif')\n",
    "# ax_right.legend(loc='lower left')\n",
    "\n",
    "# ax.set_facecolor('#f3ede2')\n",
    "# fig.set_facecolor('#f3ede2')\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
