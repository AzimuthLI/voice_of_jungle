{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import librosa\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import transformers\n",
    "from transformers import ASTConfig, ASTFeatureExtractor, ASTModel\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(log_file='log.txt'):\n",
    "    import logging\n",
    "    import sys\n",
    "    \n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(message)s')\n",
    "    # Logging to file\n",
    "    file_handler = logging.FileHandler(log_file)\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "    # Logging to console\n",
    "    ch = logging.StreamHandler(sys.stdout)\n",
    "    ch.setFormatter(formatter)\n",
    "    logger.addHandler(ch)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVE_FOLDER = \".\" #\"/content/drive/MyDrive/Colab Notebooks\"\n",
    "KEEP_COLS = ['category_number', 'common_name', 'audio_length', 'type', 'remarks', 'quality', 'scientific_name', 'mp3_link', 'region']\n",
    "\n",
    "class Config:\n",
    "    dataset_dir = f\"{DRIVE_FOLDER}/Audio_XenoCanto\"\n",
    "    labels_list = f\"{DRIVE_FOLDER}/xeno_labels.csv\"\n",
    "    model_name = \"ast_baseline\"\n",
    "    backbone_name = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "    n_classes = 397 # number of classes in the dataset\n",
    "    audio_sr = 16000 #Hz\n",
    "    segment_length = 10  #s\n",
    "    fft_window = 0.025 #s\n",
    "    hop_window_length = 0.01 #s\n",
    "    n_mels = 128\n",
    "    low_cut = 1000 #Hz\n",
    "    high_cut = 8000 #Hz\n",
    "    top_db = 100\n",
    "    batch_size = 4 \n",
    "    num_workers = 0\n",
    "    n_splits = 5\n",
    "    log_dir = f\"{DRIVE_FOLDER}/training_logs\"\n",
    "    max_lr = 1e-5\n",
    "    epochs = 5\n",
    "    weight_decay = 0.01\n",
    "    lr_final_div = 1000\n",
    "    amp = True\n",
    "    grad_accum_steps = 1\n",
    "    max_grad_norm = 1e7\n",
    "    print_epoch_freq = 1\n",
    "    print_freq = 200\n",
    "    random_seed = 2046\n",
    "    \n",
    "    @classmethod\n",
    "    def copy(cls):\n",
    "        new_class = type('CustomConfig', (cls,), {k: v for k, v in cls.__dict__.items() if not k.startswith('__') and not callable(v)})\n",
    "        return new_class\n",
    "    \n",
    "config = Config.copy()\n",
    "\n",
    "if not os.path.exists(config.log_dir):\n",
    "    os.makedirs(config.log_dir)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "seed_everything(config.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes with less than 2 samples: 72\n",
      "Number of classes in dataset: 728\n",
      "Number of samples: 11171\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>category_number</th>\n",
       "      <th>common_name</th>\n",
       "      <th>audio_length</th>\n",
       "      <th>type</th>\n",
       "      <th>remarks</th>\n",
       "      <th>quality</th>\n",
       "      <th>mp3_link</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>region</th>\n",
       "      <th>file_exists</th>\n",
       "      <th>species_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/XC228210-Blue-crowned_Manakin_B_9369_0.wav</td>\n",
       "      <td>XC228210</td>\n",
       "      <td>Blue-crowned Manakin</td>\n",
       "      <td>0:20</td>\n",
       "      <td>call</td>\n",
       "      <td>ID certainty 80%. (Archiv. tape 393 side A tra...</td>\n",
       "      <td>B</td>\n",
       "      <td>//xeno-canto.org/sounds/uploaded/OOECIWCSWV/XC...</td>\n",
       "      <td>Lepidothrix_coronata</td>\n",
       "      <td>amazonas</td>\n",
       "      <td>True</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/XC228210-Blue-crowned_Manakin_B_9369_1.wav</td>\n",
       "      <td>XC228210</td>\n",
       "      <td>Blue-crowned Manakin</td>\n",
       "      <td>0:20</td>\n",
       "      <td>call</td>\n",
       "      <td>ID certainty 80%. (Archiv. tape 393 side A tra...</td>\n",
       "      <td>B</td>\n",
       "      <td>//xeno-canto.org/sounds/uploaded/OOECIWCSWV/XC...</td>\n",
       "      <td>Lepidothrix_coronata</td>\n",
       "      <td>amazonas</td>\n",
       "      <td>True</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/XC200163-PIPCOR03_0.wav</td>\n",
       "      <td>XC200163</td>\n",
       "      <td>Blue-crowned Manakin</td>\n",
       "      <td>0:42</td>\n",
       "      <td>call, song</td>\n",
       "      <td>left bank of rio Negro - terra firme forest, w...</td>\n",
       "      <td>C</td>\n",
       "      <td>//xeno-canto.org/sounds/uploaded/DGVLLRYDXS/XC...</td>\n",
       "      <td>Lepidothrix_coronata</td>\n",
       "      <td>amazonas</td>\n",
       "      <td>True</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/XC200163-PIPCOR03_1.wav</td>\n",
       "      <td>XC200163</td>\n",
       "      <td>Blue-crowned Manakin</td>\n",
       "      <td>0:42</td>\n",
       "      <td>call, song</td>\n",
       "      <td>left bank of rio Negro - terra firme forest, w...</td>\n",
       "      <td>C</td>\n",
       "      <td>//xeno-canto.org/sounds/uploaded/DGVLLRYDXS/XC...</td>\n",
       "      <td>Lepidothrix_coronata</td>\n",
       "      <td>amazonas</td>\n",
       "      <td>True</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/XC200163-PIPCOR03_2.wav</td>\n",
       "      <td>XC200163</td>\n",
       "      <td>Blue-crowned Manakin</td>\n",
       "      <td>0:42</td>\n",
       "      <td>call, song</td>\n",
       "      <td>left bank of rio Negro - terra firme forest, w...</td>\n",
       "      <td>C</td>\n",
       "      <td>//xeno-canto.org/sounds/uploaded/DGVLLRYDXS/XC...</td>\n",
       "      <td>Lepidothrix_coronata</td>\n",
       "      <td>amazonas</td>\n",
       "      <td>True</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         file_name category_number  \\\n",
       "0  data/XC228210-Blue-crowned_Manakin_B_9369_0.wav        XC228210   \n",
       "1  data/XC228210-Blue-crowned_Manakin_B_9369_1.wav        XC228210   \n",
       "2                     data/XC200163-PIPCOR03_0.wav        XC200163   \n",
       "3                     data/XC200163-PIPCOR03_1.wav        XC200163   \n",
       "4                     data/XC200163-PIPCOR03_2.wav        XC200163   \n",
       "\n",
       "            common_name audio_length        type  \\\n",
       "0  Blue-crowned Manakin         0:20        call   \n",
       "1  Blue-crowned Manakin         0:20        call   \n",
       "2  Blue-crowned Manakin         0:42  call, song   \n",
       "3  Blue-crowned Manakin         0:42  call, song   \n",
       "4  Blue-crowned Manakin         0:42  call, song   \n",
       "\n",
       "                                             remarks quality  \\\n",
       "0  ID certainty 80%. (Archiv. tape 393 side A tra...       B   \n",
       "1  ID certainty 80%. (Archiv. tape 393 side A tra...       B   \n",
       "2  left bank of rio Negro - terra firme forest, w...       C   \n",
       "3  left bank of rio Negro - terra firme forest, w...       C   \n",
       "4  left bank of rio Negro - terra firme forest, w...       C   \n",
       "\n",
       "                                            mp3_link       scientific_name  \\\n",
       "0  //xeno-canto.org/sounds/uploaded/OOECIWCSWV/XC...  Lepidothrix_coronata   \n",
       "1  //xeno-canto.org/sounds/uploaded/OOECIWCSWV/XC...  Lepidothrix_coronata   \n",
       "2  //xeno-canto.org/sounds/uploaded/DGVLLRYDXS/XC...  Lepidothrix_coronata   \n",
       "3  //xeno-canto.org/sounds/uploaded/DGVLLRYDXS/XC...  Lepidothrix_coronata   \n",
       "4  //xeno-canto.org/sounds/uploaded/DGVLLRYDXS/XC...  Lepidothrix_coronata   \n",
       "\n",
       "     region  file_exists  species_id  \n",
       "0  amazonas         True         329  \n",
       "1  amazonas         True         329  \n",
       "2  amazonas         True         329  \n",
       "3  amazonas         True         329  \n",
       "4  amazonas         True         329  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_audio_meta = pd.read_csv(f\"{config.dataset_dir}/metadata.csv\", nrows=None)\n",
    "df_audio_meta = df_audio_meta.dropna().reset_index(drop=True)\n",
    "\n",
    "# Filter out files that do not exist\n",
    "df_audio_meta['file_exists'] = df_audio_meta['file_name'].apply(lambda x: os.path.exists(f\"{config.dataset_dir}/{x}\"))\n",
    "df_audio_meta = df_audio_meta[df_audio_meta['file_exists']].reset_index(drop=True)\n",
    "\n",
    "# parse scientific names\n",
    "df_audio_meta['scientific_name'] = df_audio_meta['scientific_name'].apply(lambda x: \"_\".join(x.split(\" \")))\n",
    "\n",
    "# drop species with less than 2 samples\n",
    "class_counts = df_audio_meta['scientific_name'].value_counts()\n",
    "print(f\"Number of classes with less than 2 samples: {len(class_counts[class_counts < 2])}\")\n",
    "\n",
    "df_audio_meta = df_audio_meta[df_audio_meta['scientific_name'].isin(class_counts[class_counts > 1].index)].copy().reset_index(drop=True)\n",
    "\n",
    "# encode scientific names to label ids\n",
    "label_ids_list = df_audio_meta['scientific_name'].unique().tolist()\n",
    "label_ids_list.sort()\n",
    "label_to_id = {label: i for i, label in enumerate(label_ids_list)}\n",
    "df_audio_meta['species_id'] = df_audio_meta['scientific_name'].map(label_to_id)\n",
    "\n",
    "# drop samples with no labels\n",
    "df_audio_meta.dropna(subset=['species_id'], inplace=True)\n",
    "df_audio_meta.reset_index(drop=True, inplace=True)\n",
    "df_audio_meta['species_id'] = df_audio_meta['species_id'].astype(int)\n",
    "\n",
    "print(f\"Number of classes in dataset: {df_audio_meta['species_id'].nunique()}\")\n",
    "print(f'Number of samples:', len(df_audio_meta))\n",
    "\n",
    "# save the number of classes in the config\n",
    "config.n_classes = df_audio_meta['species_id'].nunique()\n",
    "\n",
    "df_audio_meta.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdSongDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df_audio_meta, config):\n",
    "        self.df_audio_meta = df_audio_meta\n",
    "        self.feature_extractor = ASTFeatureExtractor()\n",
    "        self.config = config\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df_audio_meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df_audio_meta.iloc[idx]\n",
    "        audio_path = f\"{self.config.dataset_dir}/{row['file_name']}\"\n",
    "        audio_arr, sr = self.get_audio(audio_path)\n",
    "        spec = self.feature_extractor(audio_arr, sampling_rate=sr, padding=\"max_length\", return_tensors=\"pt\")\n",
    "        return spec['input_values'].squeeze(0), row['species_id']\n",
    "\n",
    "    def get_audio(self, audio_path):\n",
    "        audio, sr = librosa.load(audio_path, sr=self.config.audio_sr)\n",
    "        return audio, sr\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs = [x[0] for x in batch]\n",
    "    targets = [x[1] for x in batch]\n",
    "    data_dict = {\n",
    "        \"input_ids\": torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0),\n",
    "        \"labels\": torch.tensor(targets)\n",
    "    }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdAST(nn.Module):\n",
    "    \n",
    "    def __init__(self, backbone_name, n_classes, n_mlp_layers=1, activation='silu'):\n",
    "        super(BirdAST, self).__init__()\n",
    "        \n",
    "        # pre-trained backbone\n",
    "        backbone_config = ASTConfig.from_pretrained(backbone_name)\n",
    "        self.ast = ASTModel.from_pretrained(backbone_name, config=backbone_config)\n",
    "        self.hidden_size = backbone_config.hidden_size\n",
    "        \n",
    "        # set activation functions\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'silu':\n",
    "            self.activation = nn.SiLU()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function. Choose 'relu' or 'silu'.\")\n",
    "        \n",
    "        # define MLP layers with activation\n",
    "        layers = []\n",
    "        for _ in range(n_mlp_layers):\n",
    "            layers.append(nn.Linear(self.hidden_size, self.hidden_size))\n",
    "            layers.append(self.activation)\n",
    "        layers.append(nn.Linear(self.hidden_size, n_classes))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, spectrogram):\n",
    "        # spectrogram: (batch_size, n_mels, n_frames)\n",
    "        # output: (batch_size, n_classes)\n",
    "        \n",
    "        ast_output = self.ast(spectrogram, output_hidden_states=True) # !!! output_hidden_states=True\n",
    "        logits = self.mlp(ast_output.last_hidden_state[:, 0, :]) # Use the CLS token \n",
    "        \n",
    "        return {'logits': logits, 'hidden_states': ast_output.hidden_states}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_dataset = BirdSongDataset(df_audio_meta, config)\n",
    "bs_dataloader = DataLoader(bs_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BirdAST(config.backbone_name, config.n_classes, n_mlp_layers=1, activation='silu')\n",
    "model_weights_pth = [\n",
    "    f\"{config.log_dir}/{config.model_name}_fold_{fold_id}\" + \".pth\" for fold_id in range(config.n_splits)\n",
    "    ]\n",
    "\n",
    "for _weights in model_weights_pth:\n",
    "    assert os.path.exists(_weights), f\"Model weights file {_weights} does not exist.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(model, dataloader, checkpoint_pth=None):\n",
    "    # use only the last hidden state cls token as features for cluster\n",
    "    if checkpoint_pth is not None:\n",
    "        model.load_state_dict(torch.load(checkpoint_pth, map_location=DEVICE))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    hidden_states = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            spectrogram = batch['input_ids'].to(DEVICE)\n",
    "            output = model(spectrogram)\n",
    "            hidden_states.append(output['hidden_states'][-1][:, 0, :].cpu())\n",
    "    return torch.cat(hidden_states, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8323c6190c2443209009acecca6fa48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b040135a7e480e9d9e07285192ea6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8f51bd07de41a7bcb2d7ce207da672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dde2a16a7694a74bc8839d4fe27d872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c1eff81c624a7fbbc6f896690959ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_feat_collects = [\n",
    "    get_features(model, bs_dataloader, checkpoint_pth=model_weights_pth[i]) \n",
    "    for i in range(config.n_splits)\n",
    "    ]\n",
    "\n",
    "sample_features = torch.stack(sample_feat_collects, dim=0).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply k-means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f733d4e36144b1b13f3cbc14a466cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate wcss for different number of clusters\n",
    "wcss = []\n",
    "sil_scores = []\n",
    "\n",
    "n_clusters = np.arange(5, 100)\n",
    "for n in tqdm(n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n, random_state=config.random_seed)\n",
    "    cluster_labels = kmeans.fit_predict(sample_features)\n",
    "    sil_scores.append(silhouette_score(sample_features, cluster_labels))\n",
    "    wcss.append(kmeans.inertia_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the elbow curve\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(n_clusters, wcss, marker='o', color='b')\n",
    "ax.set_xlabel('Number of clusters')\n",
    "ax.set_ylabel('WCSS')\n",
    "ax.set_title('Elbow Curve')\n",
    "ax.grid(True)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(n_clusters, sil_scores, marker='o', color='b')\n",
    "ax.set_xlabel('Number of clusters')\n",
    "ax.set_ylabel('Silhouette Score')\n",
    "ax.set_title('Silhouette Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
